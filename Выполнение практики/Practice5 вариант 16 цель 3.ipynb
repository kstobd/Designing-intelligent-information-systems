{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Практика 5"
      ],
      "metadata": {
        "id": "Uq_kwK8gD3ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Номер варианта: 16 <br>\n",
        "Последние две цифры билета: 72"
      ],
      "metadata": {
        "id": "A2Z8ya6kDzeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "XkzJ3nLxNXbz"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Генерируем данные"
      ],
      "metadata": {
        "id": "eOvjilFbCrwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(16)\n",
        "num_samples = 1000\n",
        "num_features = 7\n",
        "\n",
        "\n",
        "data = np.random.rand(num_samples, num_features)\n",
        "data[:, 2] = data[:, 0] * 0.5 + data[:, 1] * 0.3 + \\\n",
        "    np.random.normal(0, 0.05, num_samples)\n",
        "\n",
        "columns = [f\"feature_{i+1}\" for i in range(num_features)]\n",
        "data_df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "data_df.to_csv(\"original_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "7j8Wf4RkDcGQ"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Удаляем третью целевую колонку ((номер зачетки = 72) % 7 + 1 = 3)"
      ],
      "metadata": {
        "id": "2y3GZ9NfDewW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_df.drop(columns=[\"feature_3\"], axis=1)\n",
        "y = data_df[\"feature_3\"]"
      ],
      "metadata": {
        "id": "ikGOZC6XD-EF"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разбиваем данные и нормлизуем"
      ],
      "metadata": {
        "id": "pNWJA4_XEJvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=16)\n",
        "\n",
        "# Нормализация данных для улучшения обучения моделей\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "E0TTG5EOEMfN"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем единую модель"
      ],
      "metadata": {
        "id": "me4DQ2QHEP3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(X_train_scaled.shape[1],), name=\"Input_Layer\")\n",
        "\n",
        "encoded = Dense(5, activation='relu', name=\"Encoder_Layer_1\")(input_layer)\n",
        "encoded = Dense(3, activation='relu', name=\"Encoded_Representation\")(encoded)\n",
        "\n",
        "decoded = Dense(5, activation='relu', name=\"Decoder_Layer_1\")(encoded)\n",
        "decoded = Dense(X_train_scaled.shape[1], activation='sigmoid', name=\"Decoder_Output\")(decoded)\n",
        "\n",
        "regression_output = Dense(1, activation='linear', name=\"Regression_Output\")(encoded)\n",
        "\n",
        "autoencoder_regressor = Model(inputs=input_layer, outputs=[decoded, regression_output], name=\"Autoencoder_Regressor\")"
      ],
      "metadata": {
        "id": "_dXSc5VFETw6"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Компилируем и обучаем модель"
      ],
      "metadata": {
        "id": "9qCNk-_hAQEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_regressor.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss={\"Decoder_Output\": \"mse\", \"Regression_Output\": \"mse\"},\n",
        "    loss_weights={\"Decoder_Output\": 1.0, \"Regression_Output\": 1.0},\n",
        "    metrics={\"Decoder_Output\": \"mae\", \"Regression_Output\": \"mae\"}\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', mode='min', min_delta=0.001, patience=10, restore_best_weights=False)\n",
        "\n",
        "history = autoencoder_regressor.fit(\n",
        "    X_train_scaled,\n",
        "    {\"Decoder_Output\": X_train_scaled, \"Regression_Output\": y_train},\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ8bGEojAO6y",
        "outputId": "fd5250c5-bf62-42e2-bf2c-7e2744cdd30b"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - Decoder_Output_loss: 0.0856 - Decoder_Output_mae: 0.2542 - Regression_Output_loss: 0.1609 - Regression_Output_mae: 0.3555 - loss: 0.2466 - val_Decoder_Output_loss: 0.0816 - val_Decoder_Output_mae: 0.2441 - val_Regression_Output_loss: 0.1184 - val_Regression_Output_mae: 0.2988 - val_loss: 0.2000\n",
            "Epoch 2/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0834 - Decoder_Output_mae: 0.2499 - Regression_Output_loss: 0.1192 - Regression_Output_mae: 0.2984 - loss: 0.2026 - val_Decoder_Output_loss: 0.0816 - val_Decoder_Output_mae: 0.2441 - val_Regression_Output_loss: 0.0827 - val_Regression_Output_mae: 0.2396 - val_loss: 0.1643\n",
            "Epoch 3/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0842 - Decoder_Output_mae: 0.2506 - Regression_Output_loss: 0.0842 - Regression_Output_mae: 0.2424 - loss: 0.1685 - val_Decoder_Output_loss: 0.0817 - val_Decoder_Output_mae: 0.2441 - val_Regression_Output_loss: 0.0567 - val_Regression_Output_mae: 0.1918 - val_loss: 0.1384\n",
            "Epoch 4/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0847 - Decoder_Output_mae: 0.2524 - Regression_Output_loss: 0.0546 - Regression_Output_mae: 0.1895 - loss: 0.1393 - val_Decoder_Output_loss: 0.0816 - val_Decoder_Output_mae: 0.2440 - val_Regression_Output_loss: 0.0418 - val_Regression_Output_mae: 0.1613 - val_loss: 0.1234\n",
            "Epoch 5/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0816 - Decoder_Output_mae: 0.2461 - Regression_Output_loss: 0.0409 - Regression_Output_mae: 0.1623 - loss: 0.1225 - val_Decoder_Output_loss: 0.0815 - val_Decoder_Output_mae: 0.2438 - val_Regression_Output_loss: 0.0338 - val_Regression_Output_mae: 0.1468 - val_loss: 0.1153\n",
            "Epoch 6/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0835 - Decoder_Output_mae: 0.2506 - Regression_Output_loss: 0.0322 - Regression_Output_mae: 0.1452 - loss: 0.1156 - val_Decoder_Output_loss: 0.0814 - val_Decoder_Output_mae: 0.2436 - val_Regression_Output_loss: 0.0307 - val_Regression_Output_mae: 0.1404 - val_loss: 0.1121\n",
            "Epoch 7/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0818 - Decoder_Output_mae: 0.2475 - Regression_Output_loss: 0.0293 - Regression_Output_mae: 0.1403 - loss: 0.1111 - val_Decoder_Output_loss: 0.0812 - val_Decoder_Output_mae: 0.2434 - val_Regression_Output_loss: 0.0295 - val_Regression_Output_mae: 0.1371 - val_loss: 0.1107\n",
            "Epoch 8/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0806 - Decoder_Output_mae: 0.2450 - Regression_Output_loss: 0.0304 - Regression_Output_mae: 0.1431 - loss: 0.1111 - val_Decoder_Output_loss: 0.0810 - val_Decoder_Output_mae: 0.2431 - val_Regression_Output_loss: 0.0285 - val_Regression_Output_mae: 0.1346 - val_loss: 0.1095\n",
            "Epoch 9/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0808 - Decoder_Output_mae: 0.2459 - Regression_Output_loss: 0.0304 - Regression_Output_mae: 0.1440 - loss: 0.1111 - val_Decoder_Output_loss: 0.0808 - val_Decoder_Output_mae: 0.2428 - val_Regression_Output_loss: 0.0275 - val_Regression_Output_mae: 0.1322 - val_loss: 0.1084\n",
            "Epoch 10/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0822 - Decoder_Output_mae: 0.2477 - Regression_Output_loss: 0.0289 - Regression_Output_mae: 0.1391 - loss: 0.1111 - val_Decoder_Output_loss: 0.0807 - val_Decoder_Output_mae: 0.2427 - val_Regression_Output_loss: 0.0265 - val_Regression_Output_mae: 0.1298 - val_loss: 0.1073\n",
            "Epoch 11/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0833 - Decoder_Output_mae: 0.2505 - Regression_Output_loss: 0.0277 - Regression_Output_mae: 0.1363 - loss: 0.1110 - val_Decoder_Output_loss: 0.0806 - val_Decoder_Output_mae: 0.2425 - val_Regression_Output_loss: 0.0256 - val_Regression_Output_mae: 0.1275 - val_loss: 0.1062\n",
            "Epoch 12/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0819 - Decoder_Output_mae: 0.2474 - Regression_Output_loss: 0.0277 - Regression_Output_mae: 0.1358 - loss: 0.1096 - val_Decoder_Output_loss: 0.0805 - val_Decoder_Output_mae: 0.2424 - val_Regression_Output_loss: 0.0246 - val_Regression_Output_mae: 0.1249 - val_loss: 0.1051\n",
            "Epoch 13/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Decoder_Output_loss: 0.0820 - Decoder_Output_mae: 0.2483 - Regression_Output_loss: 0.0253 - Regression_Output_mae: 0.1308 - loss: 0.1073 - val_Decoder_Output_loss: 0.0804 - val_Decoder_Output_mae: 0.2422 - val_Regression_Output_loss: 0.0235 - val_Regression_Output_mae: 0.1221 - val_loss: 0.1039\n",
            "Epoch 14/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0814 - Decoder_Output_mae: 0.2468 - Regression_Output_loss: 0.0249 - Regression_Output_mae: 0.1285 - loss: 0.1063 - val_Decoder_Output_loss: 0.0803 - val_Decoder_Output_mae: 0.2420 - val_Regression_Output_loss: 0.0223 - val_Regression_Output_mae: 0.1189 - val_loss: 0.1026\n",
            "Epoch 15/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0811 - Decoder_Output_mae: 0.2459 - Regression_Output_loss: 0.0228 - Regression_Output_mae: 0.1223 - loss: 0.1039 - val_Decoder_Output_loss: 0.0801 - val_Decoder_Output_mae: 0.2418 - val_Regression_Output_loss: 0.0211 - val_Regression_Output_mae: 0.1155 - val_loss: 0.1012\n",
            "Epoch 16/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0825 - Decoder_Output_mae: 0.2500 - Regression_Output_loss: 0.0231 - Regression_Output_mae: 0.1234 - loss: 0.1056 - val_Decoder_Output_loss: 0.0800 - val_Decoder_Output_mae: 0.2416 - val_Regression_Output_loss: 0.0198 - val_Regression_Output_mae: 0.1117 - val_loss: 0.0998\n",
            "Epoch 17/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0812 - Decoder_Output_mae: 0.2470 - Regression_Output_loss: 0.0222 - Regression_Output_mae: 0.1216 - loss: 0.1034 - val_Decoder_Output_loss: 0.0798 - val_Decoder_Output_mae: 0.2413 - val_Regression_Output_loss: 0.0185 - val_Regression_Output_mae: 0.1075 - val_loss: 0.0983\n",
            "Epoch 18/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Decoder_Output_loss: 0.0810 - Decoder_Output_mae: 0.2463 - Regression_Output_loss: 0.0193 - Regression_Output_mae: 0.1146 - loss: 0.1003 - val_Decoder_Output_loss: 0.0796 - val_Decoder_Output_mae: 0.2410 - val_Regression_Output_loss: 0.0172 - val_Regression_Output_mae: 0.1034 - val_loss: 0.0968\n",
            "Epoch 19/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0812 - Decoder_Output_mae: 0.2459 - Regression_Output_loss: 0.0188 - Regression_Output_mae: 0.1118 - loss: 0.1000 - val_Decoder_Output_loss: 0.0794 - val_Decoder_Output_mae: 0.2407 - val_Regression_Output_loss: 0.0160 - val_Regression_Output_mae: 0.0994 - val_loss: 0.0954\n",
            "Epoch 20/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0812 - Decoder_Output_mae: 0.2470 - Regression_Output_loss: 0.0171 - Regression_Output_mae: 0.1067 - loss: 0.0983 - val_Decoder_Output_loss: 0.0791 - val_Decoder_Output_mae: 0.2403 - val_Regression_Output_loss: 0.0149 - val_Regression_Output_mae: 0.0953 - val_loss: 0.0940\n",
            "Epoch 21/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0803 - Decoder_Output_mae: 0.2451 - Regression_Output_loss: 0.0157 - Regression_Output_mae: 0.1018 - loss: 0.0960 - val_Decoder_Output_loss: 0.0788 - val_Decoder_Output_mae: 0.2399 - val_Regression_Output_loss: 0.0139 - val_Regression_Output_mae: 0.0915 - val_loss: 0.0927\n",
            "Epoch 22/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0818 - Decoder_Output_mae: 0.2481 - Regression_Output_loss: 0.0139 - Regression_Output_mae: 0.0967 - loss: 0.0957 - val_Decoder_Output_loss: 0.0785 - val_Decoder_Output_mae: 0.2394 - val_Regression_Output_loss: 0.0128 - val_Regression_Output_mae: 0.0876 - val_loss: 0.0913\n",
            "Epoch 23/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0788 - Decoder_Output_mae: 0.2424 - Regression_Output_loss: 0.0123 - Regression_Output_mae: 0.0889 - loss: 0.0910 - val_Decoder_Output_loss: 0.0781 - val_Decoder_Output_mae: 0.2388 - val_Regression_Output_loss: 0.0118 - val_Regression_Output_mae: 0.0837 - val_loss: 0.0900\n",
            "Epoch 24/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0809 - Decoder_Output_mae: 0.2472 - Regression_Output_loss: 0.0119 - Regression_Output_mae: 0.0889 - loss: 0.0928 - val_Decoder_Output_loss: 0.0778 - val_Decoder_Output_mae: 0.2382 - val_Regression_Output_loss: 0.0108 - val_Regression_Output_mae: 0.0795 - val_loss: 0.0885\n",
            "Epoch 25/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0807 - Decoder_Output_mae: 0.2458 - Regression_Output_loss: 0.0117 - Regression_Output_mae: 0.0881 - loss: 0.0924 - val_Decoder_Output_loss: 0.0774 - val_Decoder_Output_mae: 0.2376 - val_Regression_Output_loss: 0.0099 - val_Regression_Output_mae: 0.0758 - val_loss: 0.0872\n",
            "Epoch 26/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0785 - Decoder_Output_mae: 0.2408 - Regression_Output_loss: 0.0102 - Regression_Output_mae: 0.0816 - loss: 0.0886 - val_Decoder_Output_loss: 0.0769 - val_Decoder_Output_mae: 0.2369 - val_Regression_Output_loss: 0.0091 - val_Regression_Output_mae: 0.0724 - val_loss: 0.0860\n",
            "Epoch 27/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0809 - Decoder_Output_mae: 0.2469 - Regression_Output_loss: 0.0094 - Regression_Output_mae: 0.0777 - loss: 0.0903 - val_Decoder_Output_loss: 0.0765 - val_Decoder_Output_mae: 0.2362 - val_Regression_Output_loss: 0.0083 - val_Regression_Output_mae: 0.0695 - val_loss: 0.0848\n",
            "Epoch 28/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Decoder_Output_loss: 0.0772 - Decoder_Output_mae: 0.2392 - Regression_Output_loss: 0.0087 - Regression_Output_mae: 0.0749 - loss: 0.0859 - val_Decoder_Output_loss: 0.0761 - val_Decoder_Output_mae: 0.2354 - val_Regression_Output_loss: 0.0077 - val_Regression_Output_mae: 0.0672 - val_loss: 0.0838\n",
            "Epoch 29/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0790 - Decoder_Output_mae: 0.2424 - Regression_Output_loss: 0.0078 - Regression_Output_mae: 0.0708 - loss: 0.0868 - val_Decoder_Output_loss: 0.0756 - val_Decoder_Output_mae: 0.2347 - val_Regression_Output_loss: 0.0072 - val_Regression_Output_mae: 0.0650 - val_loss: 0.0828\n",
            "Epoch 30/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Decoder_Output_loss: 0.0780 - Decoder_Output_mae: 0.2410 - Regression_Output_loss: 0.0078 - Regression_Output_mae: 0.0704 - loss: 0.0858 - val_Decoder_Output_loss: 0.0752 - val_Decoder_Output_mae: 0.2339 - val_Regression_Output_loss: 0.0067 - val_Regression_Output_mae: 0.0629 - val_loss: 0.0819\n",
            "Epoch 31/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0774 - Decoder_Output_mae: 0.2392 - Regression_Output_loss: 0.0067 - Regression_Output_mae: 0.0653 - loss: 0.0841 - val_Decoder_Output_loss: 0.0747 - val_Decoder_Output_mae: 0.2331 - val_Regression_Output_loss: 0.0063 - val_Regression_Output_mae: 0.0613 - val_loss: 0.0810\n",
            "Epoch 32/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0766 - Decoder_Output_mae: 0.2382 - Regression_Output_loss: 0.0064 - Regression_Output_mae: 0.0653 - loss: 0.0829 - val_Decoder_Output_loss: 0.0744 - val_Decoder_Output_mae: 0.2324 - val_Regression_Output_loss: 0.0058 - val_Regression_Output_mae: 0.0591 - val_loss: 0.0802\n",
            "Epoch 33/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0758 - Decoder_Output_mae: 0.2363 - Regression_Output_loss: 0.0059 - Regression_Output_mae: 0.0612 - loss: 0.0817 - val_Decoder_Output_loss: 0.0740 - val_Decoder_Output_mae: 0.2316 - val_Regression_Output_loss: 0.0055 - val_Regression_Output_mae: 0.0577 - val_loss: 0.0795\n",
            "Epoch 34/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Decoder_Output_loss: 0.0761 - Decoder_Output_mae: 0.2371 - Regression_Output_loss: 0.0059 - Regression_Output_mae: 0.0617 - loss: 0.0820 - val_Decoder_Output_loss: 0.0735 - val_Decoder_Output_mae: 0.2308 - val_Regression_Output_loss: 0.0053 - val_Regression_Output_mae: 0.0563 - val_loss: 0.0788\n",
            "Epoch 35/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Decoder_Output_loss: 0.0762 - Decoder_Output_mae: 0.2369 - Regression_Output_loss: 0.0050 - Regression_Output_mae: 0.0559 - loss: 0.0811 - val_Decoder_Output_loss: 0.0732 - val_Decoder_Output_mae: 0.2301 - val_Regression_Output_loss: 0.0050 - val_Regression_Output_mae: 0.0545 - val_loss: 0.0782\n",
            "Epoch 36/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0771 - Decoder_Output_mae: 0.2392 - Regression_Output_loss: 0.0047 - Regression_Output_mae: 0.0552 - loss: 0.0818 - val_Decoder_Output_loss: 0.0728 - val_Decoder_Output_mae: 0.2293 - val_Regression_Output_loss: 0.0048 - val_Regression_Output_mae: 0.0532 - val_loss: 0.0776\n",
            "Epoch 37/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0750 - Decoder_Output_mae: 0.2354 - Regression_Output_loss: 0.0046 - Regression_Output_mae: 0.0540 - loss: 0.0796 - val_Decoder_Output_loss: 0.0725 - val_Decoder_Output_mae: 0.2286 - val_Regression_Output_loss: 0.0046 - val_Regression_Output_mae: 0.0520 - val_loss: 0.0771\n",
            "Epoch 38/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0756 - Decoder_Output_mae: 0.2362 - Regression_Output_loss: 0.0042 - Regression_Output_mae: 0.0514 - loss: 0.0798 - val_Decoder_Output_loss: 0.0722 - val_Decoder_Output_mae: 0.2280 - val_Regression_Output_loss: 0.0044 - val_Regression_Output_mae: 0.0509 - val_loss: 0.0766\n",
            "Epoch 39/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0742 - Decoder_Output_mae: 0.2335 - Regression_Output_loss: 0.0042 - Regression_Output_mae: 0.0515 - loss: 0.0784 - val_Decoder_Output_loss: 0.0719 - val_Decoder_Output_mae: 0.2273 - val_Regression_Output_loss: 0.0042 - val_Regression_Output_mae: 0.0496 - val_loss: 0.0761\n",
            "Epoch 40/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0740 - Decoder_Output_mae: 0.2321 - Regression_Output_loss: 0.0040 - Regression_Output_mae: 0.0498 - loss: 0.0780 - val_Decoder_Output_loss: 0.0716 - val_Decoder_Output_mae: 0.2267 - val_Regression_Output_loss: 0.0042 - val_Regression_Output_mae: 0.0492 - val_loss: 0.0758\n",
            "Epoch 41/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Decoder_Output_loss: 0.0727 - Decoder_Output_mae: 0.2296 - Regression_Output_loss: 0.0036 - Regression_Output_mae: 0.0484 - loss: 0.0763 - val_Decoder_Output_loss: 0.0713 - val_Decoder_Output_mae: 0.2261 - val_Regression_Output_loss: 0.0040 - val_Regression_Output_mae: 0.0480 - val_loss: 0.0753\n",
            "Epoch 42/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Decoder_Output_loss: 0.0743 - Decoder_Output_mae: 0.2327 - Regression_Output_loss: 0.0034 - Regression_Output_mae: 0.0466 - loss: 0.0777 - val_Decoder_Output_loss: 0.0710 - val_Decoder_Output_mae: 0.2255 - val_Regression_Output_loss: 0.0041 - val_Regression_Output_mae: 0.0486 - val_loss: 0.0751\n",
            "Epoch 43/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0740 - Decoder_Output_mae: 0.2322 - Regression_Output_loss: 0.0035 - Regression_Output_mae: 0.0469 - loss: 0.0775 - val_Decoder_Output_loss: 0.0708 - val_Decoder_Output_mae: 0.2250 - val_Regression_Output_loss: 0.0038 - val_Regression_Output_mae: 0.0471 - val_loss: 0.0746\n",
            "Epoch 44/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0719 - Decoder_Output_mae: 0.2275 - Regression_Output_loss: 0.0037 - Regression_Output_mae: 0.0485 - loss: 0.0756 - val_Decoder_Output_loss: 0.0706 - val_Decoder_Output_mae: 0.2244 - val_Regression_Output_loss: 0.0038 - val_Regression_Output_mae: 0.0469 - val_loss: 0.0743\n",
            "Epoch 45/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0734 - Decoder_Output_mae: 0.2308 - Regression_Output_loss: 0.0032 - Regression_Output_mae: 0.0455 - loss: 0.0767 - val_Decoder_Output_loss: 0.0704 - val_Decoder_Output_mae: 0.2238 - val_Regression_Output_loss: 0.0036 - val_Regression_Output_mae: 0.0461 - val_loss: 0.0740\n",
            "Epoch 46/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0720 - Decoder_Output_mae: 0.2282 - Regression_Output_loss: 0.0032 - Regression_Output_mae: 0.0451 - loss: 0.0753 - val_Decoder_Output_loss: 0.0701 - val_Decoder_Output_mae: 0.2232 - val_Regression_Output_loss: 0.0036 - val_Regression_Output_mae: 0.0462 - val_loss: 0.0737\n",
            "Epoch 47/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0709 - Decoder_Output_mae: 0.2260 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0440 - loss: 0.0738 - val_Decoder_Output_loss: 0.0699 - val_Decoder_Output_mae: 0.2227 - val_Regression_Output_loss: 0.0036 - val_Regression_Output_mae: 0.0458 - val_loss: 0.0735\n",
            "Epoch 48/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0720 - Decoder_Output_mae: 0.2280 - Regression_Output_loss: 0.0034 - Regression_Output_mae: 0.0461 - loss: 0.0754 - val_Decoder_Output_loss: 0.0698 - val_Decoder_Output_mae: 0.2223 - val_Regression_Output_loss: 0.0035 - val_Regression_Output_mae: 0.0452 - val_loss: 0.0732\n",
            "Epoch 49/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0733 - Decoder_Output_mae: 0.2300 - Regression_Output_loss: 0.0031 - Regression_Output_mae: 0.0441 - loss: 0.0764 - val_Decoder_Output_loss: 0.0695 - val_Decoder_Output_mae: 0.2218 - val_Regression_Output_loss: 0.0034 - val_Regression_Output_mae: 0.0451 - val_loss: 0.0730\n",
            "Epoch 50/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Decoder_Output_loss: 0.0724 - Decoder_Output_mae: 0.2280 - Regression_Output_loss: 0.0028 - Regression_Output_mae: 0.0420 - loss: 0.0752 - val_Decoder_Output_loss: 0.0694 - val_Decoder_Output_mae: 0.2214 - val_Regression_Output_loss: 0.0033 - val_Regression_Output_mae: 0.0445 - val_loss: 0.0727\n",
            "Epoch 51/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0705 - Decoder_Output_mae: 0.2247 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0439 - loss: 0.0735 - val_Decoder_Output_loss: 0.0692 - val_Decoder_Output_mae: 0.2211 - val_Regression_Output_loss: 0.0035 - val_Regression_Output_mae: 0.0452 - val_loss: 0.0727\n",
            "Epoch 52/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Decoder_Output_loss: 0.0707 - Decoder_Output_mae: 0.2245 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0436 - loss: 0.0737 - val_Decoder_Output_loss: 0.0691 - val_Decoder_Output_mae: 0.2206 - val_Regression_Output_loss: 0.0033 - val_Regression_Output_mae: 0.0443 - val_loss: 0.0724\n",
            "Epoch 53/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0705 - Decoder_Output_mae: 0.2236 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0433 - loss: 0.0735 - val_Decoder_Output_loss: 0.0689 - val_Decoder_Output_mae: 0.2203 - val_Regression_Output_loss: 0.0034 - val_Regression_Output_mae: 0.0447 - val_loss: 0.0723\n",
            "Epoch 54/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0731 - Decoder_Output_mae: 0.2293 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0430 - loss: 0.0761 - val_Decoder_Output_loss: 0.0689 - val_Decoder_Output_mae: 0.2201 - val_Regression_Output_loss: 0.0032 - val_Regression_Output_mae: 0.0436 - val_loss: 0.0721\n",
            "Epoch 55/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Decoder_Output_loss: 0.0690 - Decoder_Output_mae: 0.2215 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0438 - loss: 0.0720 - val_Decoder_Output_loss: 0.0687 - val_Decoder_Output_mae: 0.2197 - val_Regression_Output_loss: 0.0033 - val_Regression_Output_mae: 0.0438 - val_loss: 0.0720\n",
            "Epoch 56/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Decoder_Output_loss: 0.0698 - Decoder_Output_mae: 0.2229 - Regression_Output_loss: 0.0033 - Regression_Output_mae: 0.0456 - loss: 0.0731 - val_Decoder_Output_loss: 0.0686 - val_Decoder_Output_mae: 0.2195 - val_Regression_Output_loss: 0.0032 - val_Regression_Output_mae: 0.0435 - val_loss: 0.0718\n",
            "Epoch 57/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Decoder_Output_loss: 0.0715 - Decoder_Output_mae: 0.2268 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0438 - loss: 0.0745 - val_Decoder_Output_loss: 0.0685 - val_Decoder_Output_mae: 0.2192 - val_Regression_Output_loss: 0.0032 - val_Regression_Output_mae: 0.0435 - val_loss: 0.0717\n",
            "Epoch 58/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Decoder_Output_loss: 0.0703 - Decoder_Output_mae: 0.2229 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0443 - loss: 0.0734 - val_Decoder_Output_loss: 0.0684 - val_Decoder_Output_mae: 0.2189 - val_Regression_Output_loss: 0.0031 - val_Regression_Output_mae: 0.0431 - val_loss: 0.0715\n",
            "Epoch 59/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Decoder_Output_loss: 0.0711 - Decoder_Output_mae: 0.2250 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0429 - loss: 0.0741 - val_Decoder_Output_loss: 0.0683 - val_Decoder_Output_mae: 0.2188 - val_Regression_Output_loss: 0.0032 - val_Regression_Output_mae: 0.0433 - val_loss: 0.0715\n",
            "Epoch 60/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Decoder_Output_loss: 0.0709 - Decoder_Output_mae: 0.2252 - Regression_Output_loss: 0.0029 - Regression_Output_mae: 0.0436 - loss: 0.0739 - val_Decoder_Output_loss: 0.0682 - val_Decoder_Output_mae: 0.2185 - val_Regression_Output_loss: 0.0033 - val_Regression_Output_mae: 0.0435 - val_loss: 0.0714\n",
            "Epoch 61/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0691 - Decoder_Output_mae: 0.2215 - Regression_Output_loss: 0.0027 - Regression_Output_mae: 0.0417 - loss: 0.0718 - val_Decoder_Output_loss: 0.0681 - val_Decoder_Output_mae: 0.2183 - val_Regression_Output_loss: 0.0031 - val_Regression_Output_mae: 0.0428 - val_loss: 0.0713\n",
            "Epoch 62/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0702 - Decoder_Output_mae: 0.2231 - Regression_Output_loss: 0.0028 - Regression_Output_mae: 0.0421 - loss: 0.0730 - val_Decoder_Output_loss: 0.0681 - val_Decoder_Output_mae: 0.2183 - val_Regression_Output_loss: 0.0032 - val_Regression_Output_mae: 0.0429 - val_loss: 0.0712\n",
            "Epoch 63/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Decoder_Output_loss: 0.0704 - Decoder_Output_mae: 0.2236 - Regression_Output_loss: 0.0027 - Regression_Output_mae: 0.0417 - loss: 0.0731 - val_Decoder_Output_loss: 0.0680 - val_Decoder_Output_mae: 0.2180 - val_Regression_Output_loss: 0.0031 - val_Regression_Output_mae: 0.0425 - val_loss: 0.0711\n",
            "Epoch 64/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0702 - Decoder_Output_mae: 0.2231 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0437 - loss: 0.0732 - val_Decoder_Output_loss: 0.0679 - val_Decoder_Output_mae: 0.2179 - val_Regression_Output_loss: 0.0031 - val_Regression_Output_mae: 0.0425 - val_loss: 0.0710\n",
            "Epoch 65/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0688 - Decoder_Output_mae: 0.2204 - Regression_Output_loss: 0.0028 - Regression_Output_mae: 0.0421 - loss: 0.0716 - val_Decoder_Output_loss: 0.0679 - val_Decoder_Output_mae: 0.2178 - val_Regression_Output_loss: 0.0032 - val_Regression_Output_mae: 0.0432 - val_loss: 0.0711\n",
            "Epoch 66/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0705 - Decoder_Output_mae: 0.2239 - Regression_Output_loss: 0.0028 - Regression_Output_mae: 0.0427 - loss: 0.0734 - val_Decoder_Output_loss: 0.0679 - val_Decoder_Output_mae: 0.2177 - val_Regression_Output_loss: 0.0031 - val_Regression_Output_mae: 0.0426 - val_loss: 0.0710\n",
            "Epoch 67/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Decoder_Output_loss: 0.0705 - Decoder_Output_mae: 0.2233 - Regression_Output_loss: 0.0029 - Regression_Output_mae: 0.0424 - loss: 0.0734 - val_Decoder_Output_loss: 0.0678 - val_Decoder_Output_mae: 0.2176 - val_Regression_Output_loss: 0.0031 - val_Regression_Output_mae: 0.0423 - val_loss: 0.0709\n",
            "Epoch 68/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0683 - Decoder_Output_mae: 0.2213 - Regression_Output_loss: 0.0028 - Regression_Output_mae: 0.0424 - loss: 0.0711 - val_Decoder_Output_loss: 0.0678 - val_Decoder_Output_mae: 0.2175 - val_Regression_Output_loss: 0.0032 - val_Regression_Output_mae: 0.0430 - val_loss: 0.0709\n",
            "Epoch 69/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0702 - Decoder_Output_mae: 0.2238 - Regression_Output_loss: 0.0028 - Regression_Output_mae: 0.0423 - loss: 0.0729 - val_Decoder_Output_loss: 0.0677 - val_Decoder_Output_mae: 0.2173 - val_Regression_Output_loss: 0.0032 - val_Regression_Output_mae: 0.0430 - val_loss: 0.0709\n",
            "Epoch 70/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0687 - Decoder_Output_mae: 0.2202 - Regression_Output_loss: 0.0030 - Regression_Output_mae: 0.0437 - loss: 0.0717 - val_Decoder_Output_loss: 0.0677 - val_Decoder_Output_mae: 0.2172 - val_Regression_Output_loss: 0.0031 - val_Regression_Output_mae: 0.0424 - val_loss: 0.0707\n",
            "Epoch 71/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Decoder_Output_loss: 0.0697 - Decoder_Output_mae: 0.2206 - Regression_Output_loss: 0.0029 - Regression_Output_mae: 0.0425 - loss: 0.0725 - val_Decoder_Output_loss: 0.0676 - val_Decoder_Output_mae: 0.2171 - val_Regression_Output_loss: 0.0032 - val_Regression_Output_mae: 0.0430 - val_loss: 0.0707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделяем модель на кодировщик, декодировщик и регрессионную модель"
      ],
      "metadata": {
        "id": "bQctmFO4AXAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(inputs=input_layer, outputs=encoded, name=\"Encoder\")\n",
        "\n",
        "encoded_input = Input(shape=(3,), name=\"Encoded_Input\")\n",
        "decoder_layer1 = autoencoder_regressor.get_layer(\"Decoder_Layer_1\")(encoded_input)\n",
        "decoder_output = autoencoder_regressor.get_layer(\"Decoder_Output\")(decoder_layer1)\n",
        "decoder = Model(inputs=encoded_input, outputs=decoder_output, name=\"Decoder\")\n",
        "\n",
        "regression_model = Model(inputs=encoded_input, outputs=autoencoder_regressor.get_layer(\"Regression_Output\")(encoded_input), name=\"Regressor\")\n"
      ],
      "metadata": {
        "id": "F5OBMqFzAeeu"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем результаты работы моделей"
      ],
      "metadata": {
        "id": "AW-BZGJrDEs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = encoder.predict(X_test_scaled, verbose=1)\n",
        "\n",
        "decoded_data = decoder.predict(encoded_data, verbose=1)\n",
        "\n",
        "predicted_regression = regression_model.predict(encoded_data, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2AmcJIADKuQ",
        "outputId": "9e519780-810e-4213-e8ed-6d6c3790685f"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем результатов работы моделей"
      ],
      "metadata": {
        "id": "3XWHfwZWE2ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(encoded_data, columns=[\"encoded_1\", \"encoded_2\", \"encoded_3\"]).to_csv(\n",
        "    \"encoded_data.csv\", index=False)\n",
        "\n",
        "pd.DataFrame(decoded_data, columns=X.columns).to_csv(\n",
        "    \"decoded_data.csv\", index=False)\n",
        "\n",
        "pd.DataFrame({\"actual\": y_test, \"predicted\": predicted_regression.flatten()}).to_csv(\n",
        "    \"regression_results.csv\", index=False)"
      ],
      "metadata": {
        "id": "ELCpK2a-E5fr"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем модели"
      ],
      "metadata": {
        "id": "sx25snogFCXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoV0MJkY-Wfc",
        "outputId": "7afd0228-dc9e-4c01-acc5-7a9597cee19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "autoencoder.save(\"autoencoder_model.h5\")\n",
        "encoder.save(\"encoder_model.h5\")\n",
        "decoder.save(\"decoder_model.h5\")\n",
        "regression_model.save(\"regression_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики для оценивания качества регрессионной модели"
      ],
      "metadata": {
        "id": "v0bhsernDQpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "mae = mean_absolute_error(y_test, predicted_regression.flatten())\n",
        "mse = mean_squared_error(y_test, predicted_regression.flatten())\n",
        "\n",
        "print(f\"Средняя абсолютная погрешность (MAE): {mae:.4f}\")\n",
        "print(f\"Среднеквадратичная погрешность (MSE): {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTIYt4TUQV2m",
        "outputId": "fe6e810d-7a27-43bc-ec29-0be9175903a6"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Средняя абсолютная погрешность (MAE): 0.0405\n",
            "Среднеквадратичная погрешность (MSE): 0.0027\n"
          ]
        }
      ]
    }
  ]
}